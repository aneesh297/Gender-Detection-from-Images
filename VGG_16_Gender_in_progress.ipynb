{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.load('summ.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(data, mean,fp_gender, im_height = 224, im_width = 224, train = True):\n",
    "    while 1:\n",
    "        for i in xrange(0, len(data)/5):\n",
    "            labels = []\n",
    "            images = np.zeros((5,224,224,3))\n",
    "            for idx, image_path in enumerate(data[5*i:5*(i+1)]):\n",
    "                img = cv2.imread('../Data/wiki_crop/' + image_path)\n",
    "                img = cv2.resize(img, (im_width, im_height))\n",
    "                images[idx,:,:,:] = img\n",
    "                if(train):\n",
    "                    labels.append(int(fp_gender[fp_gender['filepath'] == image_path]['gender']))\n",
    "\n",
    "            \n",
    "            images = images - mean\n",
    "            images = np.swapaxes(images, 1, 3)\n",
    "            images = np.swapaxes(images, 2, 3)\n",
    "            if(train):\n",
    "                labels = np.array(labels)\n",
    "                yield images, labels\n",
    "            else:\n",
    "                yield images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_gender = pd.read_csv('../Data/new_gender.csv', sep = '\\t').drop('Unnamed: 0', axis = 1)\n",
    "fp_gender.dropna(inplace = True)\n",
    "fp = fp_gender['filepath'].as_matrix()\n",
    "gender = fp_gender['gender'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_train, fp_test, gender_train, gender_test = train_test_split(fp, gender, test_size = 0.2, random_state = 5)\n",
    "fp_train, fp_cv, gender_train, gender_cv = train_test_split(fp_train, gender_train, test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fp_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5691"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gender_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_height = 224\n",
    "im_width = 224\n",
    "labels = []\n",
    "images = np.zeros((5691,224,224,3))\n",
    "for idx, image_path in enumerate(fp_cv):\n",
    "    img = cv2.imread('../Data/wiki_crop/' + image_path)\n",
    "    img = cv2.resize(img, (im_width, im_height))\n",
    "    images[idx,:,:,:] = img\n",
    "    \n",
    "    labels.append(int(fp_gender[fp_gender['filepath'] == image_path]['gender']))\n",
    "\n",
    "labels = np.array(labels)\n",
    "images = images - mean\n",
    "images = np.swapaxes(images, 1, 3)\n",
    "images = np.swapaxes(images, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu',input_shape = (3,224,224), border_mode='same', name='block1_conv1'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1'))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "# Block 3\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1'))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2'))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "# Block 4\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1'))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2'))\n",
    "model.add( Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "# Block 5\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1'))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2'))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "\n",
    "model.load_weights('../../Kaggle/Cats and Dogs/Data/vgg16_weights_th_dim_ordering_th_kernels_notop.h5')\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:18]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=rmsprop(lr = 0.0005), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fp_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17070/17071 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AeroDeath\\Miniconda2\\lib\\site-packages\\keras-1.2.2-py2.7.egg\\keras\\engine\\training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17075/17071 [==============================] - 410s - loss: 0.4466 - acc: 0.8376 - val_loss: 0.3698 - val_acc: 0.8696\n",
      "Epoch 2/10\n",
      "17075/17071 [==============================] - 412s - loss: 0.3156 - acc: 0.8900 - val_loss: 0.3379 - val_acc: 0.8831\n",
      "Epoch 3/10\n",
      "17075/17071 [==============================] - 487s - loss: 0.2867 - acc: 0.8981 - val_loss: 0.2968 - val_acc: 0.9014\n",
      "Epoch 4/10\n",
      "17075/17071 [==============================] - 440s - loss: 0.2731 - acc: 0.9043 - val_loss: 0.2992 - val_acc: 0.9027\n",
      "Epoch 5/10\n",
      "17075/17071 [==============================] - 438s - loss: 0.2671 - acc: 0.9083 - val_loss: 0.2885 - val_acc: 0.9067\n",
      "Epoch 6/10\n",
      "17075/17071 [==============================] - 502s - loss: 0.2606 - acc: 0.9123 - val_loss: 0.2908 - val_acc: 0.9065\n",
      "Epoch 7/10\n",
      "17075/17071 [==============================] - 431s - loss: 0.2541 - acc: 0.9162 - val_loss: 0.2836 - val_acc: 0.9100\n",
      "Epoch 8/10\n",
      "17075/17071 [==============================] - 493s - loss: 0.2445 - acc: 0.9204 - val_loss: 0.2827 - val_acc: 0.9086\n",
      "Epoch 9/10\n",
      "17075/17071 [==============================] - 468s - loss: 0.2390 - acc: 0.9232 - val_loss: 0.2844 - val_acc: 0.9102\n",
      "Epoch 10/10\n",
      "17075/17071 [==============================] - 459s - loss: 0.2324 - acc: 0.9257 - val_loss: 0.2807 - val_acc: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x103421ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator(fp_train, mean, fp_gender), samples_per_epoch = 17071,  nb_epoch = 10, validation_data = [images, labels],callbacks= [EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('vgg16_gender.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4134.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_cv.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}